{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Homework 3: Language Modelling in Hangman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Student Name: Yu Dong\n",
    "\n",
    "Student ID: 928922"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Due date</b>:  Friday, 17 May 2019 4pm\n",
    "\n",
    "<b>Submission method</b>: see LMS\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -20% per day\n",
    "\n",
    "<b>Marks</b>: 7% of mark for class (with 6% on correctness + 1% on quality and efficiency of your code)\n",
    "\n",
    "<b>Materials</b>: See the main class LMS page for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib and Scikit-Learn. In particular, if you are not using a lab computer which already has it installed, we recommend installing all the data for NLTK, since you will need various parts of it to complete this assignment. You can also use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>. \n",
    "\n",
    "To familiarize yourself with NLTK, here is a free online book:  Steven Bird, Ewan Klein, and Edward Loper (2009). <a href=http://nltk.org/book>Natural Language Processing with Python</a>. O'Reilly Media Inc. You may also consult the <a href=https://www.nltk.org/api/nltk.html>NLTK API</a>.\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via LMS. Minor changes and clarifications will be announced in the forum on LMS, we recommend you check the forum regularly.\n",
    "\n",
    "<b>Academic Misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this homework, you'll be creating an 'artificial intelligence' player for the classic Hangman word guessing game. You will need to implement several different automatic strategies based on character level language models. Your objective is to create an automatic player which makes the fewest mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The Hangman Game (*No implementation is needed*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The <a href=\"https://en.wikipedia.org/wiki/Hangman_(game)\">Hangman game</a> is a simple game whereby one person thinks of a word, which they keep secret from their opponent, who tries to guess the word one character at a time. The game ends when the opponent makes more than a fixed number of incorrect guesses, or they figure out the secret word before then (in which case they *win*). \n",
    "\n",
    "Here's a simple version of the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hangman(secret_word, guesser, max_mistakes=8, verbose=True, **guesser_args):\n",
    "    \"\"\"\n",
    "        This function plays the hangman game with the provided gusser and returns the number of incorrect guesses. \n",
    "        \n",
    "        secret_word: a string of lower-case alphabetic characters, i.e., the answer to the game\n",
    "        guesser: a function which guesses the next character at each stage in the game\n",
    "            The function takes a:\n",
    "                mask: what is known of the word, as a string with _ denoting an unknown character\n",
    "                guessed: the set of characters which already been guessed in the game\n",
    "                guesser_args: additional (optional) keyword arguments, i.e., name=value\n",
    "        max_mistakes: limit on length of game, in terms of allowed mistakes\n",
    "        verbose: be chatty vs silent\n",
    "        guesser_args: keyword arguments to pass directly to the guesser function\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.lower()\n",
    "    mask = ['_'] * len(secret_word)\n",
    "    guessed = set()\n",
    "    if verbose:\n",
    "        print(\"Starting hangman game. Target is\", ' '.join(mask), 'length', len(secret_word))\n",
    "    \n",
    "    mistakes = 0\n",
    "    while mistakes < max_mistakes:\n",
    "        if verbose:\n",
    "            print(\"You have\", (max_mistakes-mistakes), \"attempts remaining.\")\n",
    "        guess = guesser(mask, guessed, **guesser_args)\n",
    "\n",
    "        if verbose:\n",
    "            print('Guess is', guess)\n",
    "        if guess in guessed:\n",
    "            if verbose:\n",
    "                print('Already guessed this before.')\n",
    "            mistakes += 1\n",
    "        else:\n",
    "            guessed.add(guess)\n",
    "            if guess in secret_word:\n",
    "                for i, c in enumerate(secret_word):\n",
    "                    if c == guess:\n",
    "                        mask[i] = c\n",
    "                if verbose:\n",
    "                    print('Good guess:', ' '.join(mask))\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Sorry, try again.')\n",
    "                mistakes += 1\n",
    "                \n",
    "        if '_' not in mask:\n",
    "            if verbose:\n",
    "                print('Congratulations, you won.')\n",
    "            return mistakes\n",
    "        \n",
    "    if verbose:\n",
    "        print('Out of guesses. The word was', secret_word)    \n",
    "    return mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here is a human guesser allowing interactive play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def human(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "    This is a simple function for manual play.\n",
    "    \"\"\"\n",
    "    print('Enter your guess:')\n",
    "    return input().lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you want to play hangman interactively, please set `interactive` to True. When submitting your solution, set to False so we can automatically run the whole notebook using `Run All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can play the game interactively using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ _ length 8\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "a\n",
      "Guess is a\n",
      "Good guess: _ _ a _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "e\n",
      "Guess is e\n",
      "Good guess: _ _ a _ e _ e _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "c\n",
      "Guess is c\n",
      "Sorry, try again.\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "v\n",
      "Guess is v\n",
      "Good guess: _ _ a _ e v e _\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "r\n",
      "Guess is r\n",
      "Good guess: _ _ a _ e v e r\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "w\n",
      "Guess is w\n",
      "Good guess: w _ a _ e v e r\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "h\n",
      "Guess is h\n",
      "Good guess: w h a _ e v e r\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "t\n",
      "Guess is t\n",
      "Good guess: w h a t e v e r\n",
      "Congratulations, you won.\n"
     ]
    }
   ],
   "source": [
    "if interactive:\n",
    "    hangman('whatever', human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Preparing Test Set and Training Set (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Instructions</b>: We will be using the words occurring in the *Brown* corpus for *training* an artificial intelligence guessing algorithm, and for *evaluating* the quality of the algorithm. Note that we are intentionally making the hangman game hard, as the AI will need to cope with test words that it has not seen before, hence it will need to learn generalisable patterns of characters to make reasonable predictions.\n",
    "\n",
    "Your first task is to compute the unique word types occurring in the *Brown* corpus, using `nltk.corpus.Brown` and the `words` method, selecting only words that are entirely comprised of alphabetic characters, and lowercasing the words. Finally, randomly shuffle (`numpy.random.shuffle`) this collection of word types, and split them into disjoint training and testing sets. The test set should contain 1000 word types, and the rest should be in the training set. Your code should print the sizes of the training and test sets.\n",
    "\n",
    "Feel free to test your own Hangman performance using `hangman(numpy.random.choice(test_set), human, 8, True)`. It is surprisingly difficult (and addictive)!\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40234\n",
      "1000\n",
      "39234\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "# word_set stores all the unique word types in the Brown corpus\n",
    "word_set = []\n",
    "# test_set stores 1000 word types for testing\n",
    "test_set = []\n",
    "# training_set stores the rest word types for training\n",
    "training_set = []\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "#process paragraph in brown, use a set to store the words in each paragraph.\n",
    "wordset = set()\n",
    "#remove the character which cannot match a-zA-Z and lowercase the word\n",
    "for word in brown.words():\n",
    "    if re.match(r'^[a-zA-Z]+$',word):\n",
    "        if word.lower() not in wordset:\n",
    "            wordset.add(word.lower())\n",
    "#split test set and training set\n",
    "word_set = np.asarray(list(wordset))\n",
    "np.random.shuffle(word_set)\n",
    "test_set = word_set[:1000]\n",
    "training_set = word_set[1000:]\n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(len(word_set))\n",
    "print(len(test_set))\n",
    "print(len(training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(len(word_set) > 35000 and len(word_set) < 45000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(len(test_set) == 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(len(training_set) + len(test_set) == len(word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ length 7\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "a\n",
      "Guess is a\n",
      "Sorry, try again.\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "c\n",
      "Guess is c\n",
      "Sorry, try again.\n",
      "You have 6 attempts remaining.\n",
      "Enter your guess:\n",
      "e\n",
      "Guess is e\n",
      "Good guess: _ e _ _ _ _ _\n",
      "You have 6 attempts remaining.\n",
      "Enter your guess:\n",
      "i\n",
      "Guess is i\n",
      "Good guess: _ e _ _ i _ _\n",
      "You have 6 attempts remaining.\n",
      "Enter your guess:\n",
      "q\n",
      "Guess is q\n",
      "Sorry, try again.\n",
      "You have 5 attempts remaining.\n",
      "Enter your guess:\n",
      "y\n",
      "Guess is y\n",
      "Sorry, try again.\n",
      "You have 4 attempts remaining.\n",
      "Enter your guess:\n",
      "n\n",
      "Guess is n\n",
      "Good guess: _ e _ _ i n _\n",
      "You have 4 attempts remaining.\n",
      "Enter your guess:\n",
      "l\n",
      "Guess is l\n",
      "Good guess: _ e l _ i n _\n",
      "You have 4 attempts remaining.\n",
      "Enter your guess:\n",
      "g\n",
      "Guess is g\n",
      "Good guess: _ e l _ i n g\n",
      "You have 4 attempts remaining.\n",
      "Enter your guess:\n",
      "b\n",
      "Guess is b\n",
      "Sorry, try again.\n",
      "You have 3 attempts remaining.\n",
      "Enter your guess:\n",
      "d\n",
      "Guess is d\n",
      "Sorry, try again.\n",
      "You have 2 attempts remaining.\n",
      "Enter your guess:\n",
      "f\n",
      "Guess is f\n",
      "Sorry, try again.\n",
      "You have 1 attempts remaining.\n",
      "Enter your guess:\n",
      "r\n",
      "Guess is r\n",
      "Sorry, try again.\n",
      "Out of guesses. The word was helping\n"
     ]
    }
   ],
   "source": [
    "if interactive:\n",
    "    hangman(np.random.choice(test_set), human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Simple Guesser: Random Guessing (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Instructions</b>: To set a baseline, your first *AI* attempt will be a trivial random method. For this you should implement a guessing method, similar to the `human` method above, i.e., using the same input arguments and returning a character. Your method should randomly choose a character from the range `'a'...'z'` after excluding the characters that have already been guessed in the current game (all subsequent AI approaches should also exclude previous guesses). You might want to use `numpy.random.choice` for this purpose.\n",
    "\n",
    "To help you measure the performance of this (and later) guesser, a `test_guesser` method that takes a guesser and measures the average number of incorrect guesses made over all the words in the `test_set` is provided to you. \n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_guesser(guesser, test=test_set):\n",
    "    \"\"\"\n",
    "        This function takes a guesser and measures the average number of incorrect guesses made over all the words in the test_set. \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for word in test:\n",
    "        total += hangman(word, guesser, 26, False)\n",
    "    return total / float(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of incorrect guesses:  16.702\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def random_guesser(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "        This function implements a random guesser. It returns the random guess. \n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    \n",
    "    #create a alphabetic characters list\n",
    "    alpha_list = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "    #create a list to store guessed characters\n",
    "    store_guessed = [i for i in guessed]\n",
    "    #create a list to store the character that can be selected\n",
    "    choice_list = []\n",
    "    #select characeters from alphabetic list which is not in guessed list\n",
    "    for i in alpha_list:\n",
    "        if i not in store_guessed:\n",
    "            choice_list.append(i)\n",
    "    return np.random.choice(choice_list)\n",
    "\n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "# uncomment to run a single hangman game with output shown (useful for debugging)\n",
    "#hangman(np.random.choice(test_set), random_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(random_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(result > 10 and result < 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Your First AI Guesser: Unigram Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Instructions:** As your first real AI, you should train a *unigram* model over the training set.  This requires you to find the frequencies of characters over all training words. Using this model, you should write a guesser that returns the character with the highest probability. Remember to exclude already guessed characters. \n",
    "\n",
    "Hint: It should be much lower than random guessing.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'e': 35188, 'i': 26057, 'a': 24369, 's': 23688, 'n': 22611, 'r': 22102, 't': 20667, 'o': 19184, 'l': 16667, 'c': 12618, 'd': 12276, 'u': 10206, 'm': 8704, 'g': 8610, 'p': 8514, 'h': 7339, 'b': 5730, 'y': 5367, 'f': 4223, 'v': 3439, 'k': 2979, 'w': 2815, 'z': 1035, 'x': 833, 'j': 637, 'q': 534})\n",
      "\n",
      "Average number of incorrect guesses:  10.366\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# unigram_counts stores the frequencies of characters over all training words\n",
    "unigram_counts = Counter()\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "for word in training_set:\n",
    "    for character in word:\n",
    "        unigram_counts[character] += 1\n",
    "        \n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(unigram_counts)\n",
    "\n",
    "def unigram_guesser(mask, guessed, unigram_counts=unigram_counts):\n",
    "    \"\"\"\n",
    "        This function implements a unigram guesser. It returns a guess based on the unigram model. \n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    \n",
    "    #create a order list to store the characeters with highest frequencies\n",
    "    order_list = []\n",
    "    #create a list to store guessed characters\n",
    "    store_guessed = [i for i in guessed]\n",
    "    #append the character to order list if it has highest frequency\n",
    "    for (char,_) in unigram_counts.most_common():\n",
    "        order_list.append(char)\n",
    "    #select character from order list if it is not in guessed list\n",
    "    for i in order_list:\n",
    "        if i not in store_guessed:\n",
    "            return i\n",
    "        \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "#hangman(np.random.choice(test_set), unigram_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(unigram_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(result > 5 and result < 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Your Second AI Guesser: Length-based Unigram Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Instructions:** The length of the secret word is an important clue that we might exploit. Different length words tend to have different distributions over characters, e.g., short words are less likely to have suffixes or prefixes. You should incorporate this idea by conditioning the unigram model on the length of the secret word, i.e., having a *different* unigram model for each length of the words. You will need to be a little careful at test time, to be robust to the (unlikely) situation that you encounter a word length that you didn't see in training. You need to decide on how to handle this situation.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "\n",
      "defaultdict(<class 'collections.Counter'>, {1: Counter({'b': 1, 'a': 1, 'x': 1, 'm': 1, 'o': 1, 't': 1, 'u': 1, 's': 1, 'g': 1, 'n': 1, 'p': 1, 'z': 1, 'y': 1, 'c': 1, 'e': 1, 'r': 1, 'w': 1, 'f': 1, 'k': 1, 'd': 1, 'h': 1, 'i': 1, 'l': 1, 'j': 1, 'q': 1, 'v': 1}), 2: Counter({'a': 24, 'e': 21, 'o': 19, 'm': 19, 's': 18, 'i': 16, 'l': 13, 'p': 12, 'h': 12, 't': 11, 'u': 11, 'n': 11, 'c': 10, 'f': 10, 'd': 10, 'r': 9, 'b': 8, 'w': 7, 'y': 6, 'g': 6, 'v': 6, 'k': 5, 'j': 5, 'x': 2, 'q': 2, 'z': 1}), 3: Counter({'a': 238, 'e': 198, 'o': 178, 'i': 129, 'n': 117, 's': 113, 't': 112, 'm': 103, 'u': 101, 'p': 101, 'd': 100, 'r': 99, 'b': 90, 'l': 79, 'g': 76, 'y': 75, 'w': 74, 'h': 74, 'c': 70, 'f': 51, 'k': 32, 'j': 28, 'v': 25, 'x': 22, 'z': 10, 'q': 6}), 4: Counter({'e': 894, 'a': 864, 's': 686, 'o': 676, 'l': 555, 'i': 533, 'r': 523, 't': 487, 'n': 466, 'd': 360, 'u': 350, 'm': 295, 'h': 290, 'p': 282, 'c': 257, 'b': 252, 'k': 224, 'g': 223, 'w': 194, 'y': 178, 'f': 168, 'v': 93, 'j': 62, 'z': 44, 'x': 36, 'q': 8}), 5: Counter({'e': 2215, 'a': 1827, 's': 1824, 'r': 1371, 'o': 1332, 'l': 1192, 'i': 1154, 't': 1081, 'n': 1033, 'd': 771, 'c': 704, 'u': 677, 'h': 593, 'm': 574, 'y': 548, 'p': 532, 'b': 499, 'g': 466, 'k': 382, 'f': 345, 'w': 297, 'v': 239, 'z': 87, 'j': 76, 'x': 67, 'q': 29}), 6: Counter({'e': 4221, 'a': 2699, 's': 2591, 'r': 2524, 'i': 2033, 'n': 1998, 'o': 1968, 'l': 1944, 't': 1861, 'd': 1625, 'u': 1146, 'c': 1045, 'm': 938, 'g': 891, 'h': 870, 'p': 850, 'b': 775, 'y': 715, 'f': 498, 'k': 445, 'w': 431, 'v': 391, 'z': 123, 'j': 104, 'x': 90, 'q': 50}), 7: Counter({'e': 5329, 'a': 3546, 's': 3461, 'r': 3421, 'i': 3353, 'n': 3049, 't': 2668, 'o': 2518, 'l': 2483, 'd': 2053, 'c': 1691, 'u': 1506, 'g': 1485, 'm': 1247, 'p': 1234, 'h': 1104, 'b': 948, 'y': 747, 'f': 674, 'k': 583, 'w': 531, 'v': 467, 'z': 155, 'x': 111, 'j': 95, 'q': 82}), 8: Counter({'e': 5590, 'i': 3879, 's': 3666, 'a': 3652, 'n': 3484, 'r': 3474, 't': 2895, 'o': 2779, 'l': 2617, 'd': 2208, 'c': 1939, 'u': 1571, 'g': 1513, 'm': 1301, 'p': 1216, 'h': 1162, 'b': 848, 'y': 713, 'f': 710, 'v': 538, 'k': 512, 'w': 478, 'z': 115, 'x': 109, 'q': 84, 'j': 83}), 9: Counter({'e': 5442, 'i': 3936, 'n': 3468, 's': 3467, 'a': 3458, 'r': 3276, 't': 3069, 'o': 2622, 'l': 2326, 'c': 1916, 'd': 1870, 'u': 1449, 'g': 1370, 'm': 1246, 'p': 1160, 'h': 1032, 'b': 756, 'y': 647, 'f': 584, 'v': 536, 'w': 376, 'k': 375, 'z': 134, 'x': 123, 'q': 88, 'j': 67}), 10: Counter({'e': 4334, 'i': 3640, 'n': 3088, 's': 2906, 't': 2793, 'a': 2784, 'r': 2675, 'o': 2395, 'l': 1947, 'c': 1675, 'd': 1413, 'u': 1301, 'g': 1098, 'p': 1069, 'm': 1056, 'h': 826, 'b': 617, 'y': 552, 'f': 464, 'v': 452, 'w': 211, 'k': 177, 'z': 114, 'x': 98, 'q': 68, 'j': 57}), 11: Counter({'e': 2944, 'i': 2748, 'n': 2264, 't': 2159, 'a': 2007, 's': 2005, 'r': 1922, 'o': 1708, 'l': 1310, 'c': 1222, 'u': 862, 'd': 811, 'p': 775, 'm': 738, 'g': 629, 'h': 515, 'b': 422, 'y': 415, 'f': 300, 'v': 286, 'k': 134, 'w': 123, 'x': 72, 'z': 67, 'q': 45, 'j': 27}), 12: Counter({'e': 1908, 'i': 1899, 'n': 1553, 't': 1472, 'a': 1429, 's': 1312, 'r': 1262, 'o': 1225, 'l': 980, 'c': 904, 'u': 585, 'p': 547, 'm': 525, 'd': 507, 'g': 394, 'h': 379, 'y': 300, 'b': 261, 'f': 197, 'v': 196, 'z': 72, 'k': 54, 'w': 53, 'x': 40, 'q': 37, 'j': 17}), 13: Counter({'i': 1296, 'e': 1048, 'n': 1036, 't': 980, 'a': 922, 'o': 848, 's': 801, 'r': 754, 'c': 579, 'l': 552, 'p': 360, 'm': 350, 'u': 337, 'd': 261, 'g': 247, 'y': 208, 'h': 206, 'b': 142, 'v': 116, 'f': 115, 'z': 37, 'x': 35, 'k': 28, 'w': 22, 'q': 20, 'j': 10}), 14: Counter({'i': 707, 'e': 566, 'n': 540, 't': 520, 'a': 458, 's': 449, 'o': 446, 'r': 389, 'l': 330, 'c': 302, 'p': 174, 'u': 169, 'm': 163, 'd': 150, 'h': 128, 'y': 116, 'g': 116, 'b': 68, 'v': 62, 'f': 61, 'z': 34, 'x': 12, 'k': 11, 'w': 10, 'q': 8, 'j': 3}), 15: Counter({'i': 400, 't': 282, 'n': 276, 'e': 247, 'o': 246, 'a': 235, 's': 207, 'r': 197, 'l': 168, 'c': 165, 'p': 108, 'y': 80, 'u': 75, 'm': 72, 'd': 71, 'h': 67, 'g': 51, 'f': 25, 'b': 24, 'v': 20, 'z': 18, 'x': 8, 'k': 8, 'w': 5, 'q': 4, 'j': 1}), 16: Counter({'i': 171, 't': 134, 'a': 111, 'n': 111, 'e': 108, 'o': 105, 'r': 95, 'l': 91, 's': 89, 'c': 64, 'p': 46, 'h': 36, 'm': 35, 'y': 33, 'u': 32, 'd': 27, 'g': 22, 'b': 11, 'z': 10, 'f': 10, 'x': 6, 'v': 6, 'k': 4, 'q': 2, 'w': 1}), 17: Counter({'i': 91, 't': 79, 'a': 71, 'e': 70, 'n': 66, 'r': 64, 'o': 58, 's': 44, 'l': 42, 'c': 39, 'p': 27, 'm': 26, 'h': 26, 'd': 23, 'y': 20, 'u': 17, 'g': 12, 'z': 8, 'b': 5, 'v': 4, 'f': 3, 'x': 1, 'w': 1, 'k': 1, 'j': 1}), 18: Counter({'i': 48, 't': 44, 'e': 37, 's': 35, 'r': 34, 'o': 33, 'n': 29, 'a': 25, 'c': 24, 'l': 23, 'p': 14, 'h': 13, 'd': 12, 'y': 10, 'm': 9, 'u': 8, 'g': 6, 'f': 4, 'b': 2, 'k': 2, 'z': 1, 'v': 1}), 19: Counter({'o': 18, 'i': 15, 'n': 14, 't': 13, 'a': 11, 'r': 9, 'e': 8, 'c': 7, 's': 7, 'l': 7, 'u': 5, 'm': 3, 'd': 3, 'g': 3, 'p': 3, 'z': 2, 'f': 2, 'h': 2, 'y': 1}), 20: Counter({'i': 5, 't': 4, 'n': 3, 'a': 2, 'o': 2, 'u': 1, 'z': 1, 's': 1, 'l': 1}), 21: Counter({'o': 6, 'c': 4, 'm': 3, 'a': 3, 's': 3, 'e': 3, 'r': 3, 'i': 3, 'l': 3, 'h': 3, 'p': 3, 't': 1, 'u': 1, 'g': 1, 'n': 1, 'y': 1}), 22: Counter({'e': 4, 'n': 3, 'l': 3, 'a': 2, 's': 2, 'z': 1, 'y': 1, 'f': 1, 'k': 1, 'b': 1, 'o': 1, 't': 1, 'u': 1})})\n",
      "\n",
      "Average number of incorrect guesses:  10.292\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# unigram_counts_by_length stores a dictionary, mapping word length to the frequencies of characters of words with that word length\n",
    "unigram_counts_by_length = defaultdict(Counter)\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "for word in training_set:\n",
    "    for character in word:\n",
    "        unigram_counts_by_length[len(word)][character] += 1\n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "lengths = sorted(unigram_counts_by_length.keys())\n",
    "max_length = lengths[-1] + 1\n",
    "print(lengths)\n",
    "print()\n",
    "print(unigram_counts_by_length)\n",
    "\n",
    "def unigram_length_guesser(mask, guessed, counts=unigram_counts_by_length):\n",
    "    \"\"\"\n",
    "        This function implements a length-based unigram guesser. It returns a guess based on the length-based unigram model. \n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    \n",
    "    #create alphabetic set to store 26 characters\n",
    "    alpha_set = {'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'}\n",
    "    #if the length of the word not in lengths, make random choice from unguessed alphabetic set\n",
    "    if len(mask) not in lengths:\n",
    "        return np.random.choice(list(alpha_set-guessed))\n",
    "    #create a list to store characters with highest frequencies for each length of word\n",
    "    order_list = []\n",
    "    for (char, _) in unigram_counts_by_length[len(mask)].most_common():\n",
    "        order_list.append(char)\n",
    "        for i in order_list:\n",
    "            if i not in guessed:\n",
    "                return i\n",
    "    return np.random.choice(list(alpha_set-guessed))\n",
    "    \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "#hangman(np.random.choice(test_set), unigram_length_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(unigram_length_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(result > 5 and result < 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Your Third AI Guesser: Bigram Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Instructions:** Now for the next challenge, using a *bigram* language model over characters. The order of characters is obviously important, yet this wasn't incorporated in any of the above models. Knowing that the word has the sequence `n _ s s` is a pretty strong clue that the missing character might be `e`. Similarly the distribution over characters that start or end a word are highly biased (e.g., toward common prefixes and suffixes, like *un-*, *-ed* and *-ly*).\n",
    "\n",
    "You should develop a *bigram* language model over characters, train this over the training words (being careful to handle the start of each word properly, e.g., by padding with a sentinel symbol `$`.) You should use *linear interpolation* to smooth between the higher order and lower order models, and you will have to decide how to weight each component (be reminded that all probabilities should sum to 1).\n",
    "\n",
    "Your bigram guesser should apply your language model to each blank position in the secret word by using the left context as is known. E.g., in the partial word `$ _ e c _ e _ _` we know the left context for the first three blanks, but have no known left context for the last blank. Using a bigram language model, we are able to apply it to the first three blanks only. You should then select the character with the highest probability of predicting the most number of correct entries over the blanks. \n",
    "\n",
    "Do you see any improvement over the unigram guessers above?\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of incorrect guesses:  8.654\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "bigram_counts = defaultdict(Counter) # you will want a different data structure to store the bigram \n",
    "for word in training_set:\n",
    "    word = \"$\" + word\n",
    "    bigram_list = zip(word[:-1], word[1:])\n",
    "    for bigram in bigram_list:\n",
    "        first, second = bigram\n",
    "        bigram_counts[first][second] += 1\n",
    "#print(bigram_counts)\n",
    "          \n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "import math\n",
    "#input the character, previous characters, bigram_counts and the weight of bigram model\n",
    "#return the probability of interpolation\n",
    "def get_prob_interp(prev_char, char, bigram_counts, lambdas):\n",
    "    total_count = float(sum(bigram_counts[prev_char].values()))\n",
    "    interp_prob = 0.0\n",
    "    if total_count != 0:\n",
    "        interp_prob = bigram_counts[prev_char][char] / total_count\n",
    "    return lambdas * interp_prob + (1 - lambdas) * unigram_counts[char] / float(sum(unigram_counts.values()))\n",
    "def get_log_prob_interp(chars_list, char, bigram_counts, lambdas):\n",
    "    log_prob = 0\n",
    "    for _, chars in enumerate(chars_list):\n",
    "        if len(chars) >= 2:\n",
    "            chars = chars[-1:]\n",
    "        log_prob += math.log(get_prob_interp(chars, char, bigram_counts, lambdas))\n",
    "    return log_prob\n",
    "\n",
    "def bigram_guesser(mask, guessed, counts=bigram_counts): # add extra default arguments if needed\n",
    "    \"\"\"\n",
    "        This function implements a bigram guesser. It returns a guess based on the bigram model using linear interpolation.\n",
    "    \"\"\"\n",
    "    ###\n",
    "    # Your answer BEGINS HERE\n",
    "    ###\n",
    "    \n",
    "    #use weighted bigram model to get the character with highest probability\n",
    "    #the higher weight of bigram model, the lower average number of incorrect guesses\n",
    "    mask = \"$\" + \"\".join(mask)\n",
    "    chars_list = mask.split(\"_\")[:-1]\n",
    "    char_prob = dict()\n",
    "    alpha_list = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "    for i in alpha_list:\n",
    "        if not i in guessed:\n",
    "            char_prob[i] = get_log_prob_interp(chars_list, i, bigram_counts, 0.9)\n",
    "    return max(char_prob, key=char_prob.get)\n",
    "    \n",
    "    ###\n",
    "    # Your answer ENDS HERE\n",
    "    ###\n",
    "\n",
    "#hangman(np.random.choice(test_set), bigram_guesser, 10, True)\n",
    "\n",
    "result = test_guesser(bigram_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(result < 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Your Own AI Guesser (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Instructions:** You should try to develop a more effective AI, `my_ai_guesser`, for hangman. Feel free to engage your creativity here! Possibilities include better conditioning on the length of the word, fancier smoothing methods, and using ngram models. Ensure you report the test performance of your guesser. Have fun!\n",
    "\n",
    "You will be marked based on the explanation of your approach and its accuracy. \n",
    "\n",
    "(1 mark) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of incorrect guesses:  8.23\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "trigram_counts = defaultdict(Counter) # you will want a different data structure to store the bigram \n",
    "for word in training_set:\n",
    "    word = \"$$\" + word\n",
    "    trigram_list = [word[i:i+3] for i,_ in enumerate(word[:-2])]\n",
    "    for trigram in trigram_list:\n",
    "        first, second = trigram[:-1], trigram[-1]\n",
    "        trigram_counts[first][second] += 1\n",
    "#print(trigram_counts)\n",
    "\n",
    "def get_prob_interp(prev_char, char, trigram_counts, lambdas):\n",
    "    total_count = float(sum(trigram_counts[prev_char].values()))\n",
    "    interp_prob = 0.0\n",
    "    if total_count!=0:\n",
    "        interp_prob = trigram_counts[prev_char][char] / total_count\n",
    "    return lambdas * interp_prob + (1 - lambdas) * unigram_counts[char] / float(sum(unigram_counts.values()))\n",
    "def get_log_prob_interp(chars_list, char, trigram_counts, lambdas):\n",
    "    log_prob = 0\n",
    "    for index, chars in enumerate(chars_list):\n",
    "        if len(chars) >= 3:\n",
    "            chars = chars[-2:]\n",
    "        log_prob += math.log(get_prob_interp(chars, char, trigram_counts, lambdas))\n",
    "    return log_prob\n",
    "def my_ai_guesser(mask, guessed,counts=trigram_counts):\n",
    "    mask = \"$$\" + \"\".join(mask)\n",
    "    chars_list = mask.split(\"_\")[:-1]\n",
    "    char_prob = dict()\n",
    "    alpha_list = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "    for i in alpha_list:\n",
    "        if not i in guessed:\n",
    "            char_prob[i] = get_log_prob_interp(chars_list, i, trigram_counts, 0.9)\n",
    "    return max(char_prob, key=char_prob.get)\n",
    "\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "result = test_guesser(my_ai_guesser)\n",
    "print()\n",
    "print(\"Average number of incorrect guesses: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Instructions:** Explain your approach and discuss your result below. Please keep it brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "The above guesser is based on trigram model. The method weight the higher order model(trigram model) and lower order \n",
    "model (unigram model). The sum of weight probability is one. The guesser selects the character with highest probability.\n",
    "The result of average number of incorrect guesses shows my_ai_guesser has better performance than previous guessers. \n",
    "Meanwhile, the higher weight of trigram model, the lower average number of incorrect guesses. Because trigram model \n",
    "selects character based on two previous characters, the unigram model selects character based on the frequency of \n",
    "character. The selection based on relationship between two previous characters will be more precise than the selection \n",
    "merely based on character frequency. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
